#AIçº¯ç”Ÿæˆå™¨ï¼Œä¸æ¶‰åŠä»»ä½•ä¸šåŠ¡é€»è¾‘ï¼Œåº”æ”¾å…¥GPT/
import time
import random
from typing import Optional, Callable, AsyncGenerator

class AICompletionPort:
    def __init__(self, gpt_caller):
        self.gpt = gpt_caller

    async def generate_reply(self, role_data, history, user_input, timeout=30, session_context_source=None, on_partial_reply: Optional[Callable[[str], None]] = None):
        """
        ç”ŸæˆAIå›å¤
        
        Args:
            role_data: è§’è‰²é…ç½®æ•°æ®
            history: ä¼šè¯å†å²æ¶ˆæ¯
            user_input: å½“å‰ç”¨æˆ·è¾“å…¥
            timeout: è¶…æ—¶æ—¶é—´
            session_context_source: ä¼šè¯ä¸Šä¸‹æ–‡æ¥æºæ ‡è®°ï¼Œ"snapshot" è¡¨ç¤ºæ¥è‡ªå¿«ç…§ä¼šè¯
        
        è¯´æ˜ï¼š
            - å¸¸è§„ä¼šè¯: system_prompt + role_data.history + MessageServiceå†å²
            - å¿«ç…§ä¼šè¯: system_prompt + MessageServiceå†å²ï¼ˆå·²å«å¿«ç…§å®Œæ•´ä¸Šä¸‹æ–‡ï¼Œè·³è¿‡role_data.historyé¿å…é‡å¤ï¼‰
        """
        # æ‰“å°è¾“å…¥çš„å†å²è®°å½•
        print(f"ğŸ§  AIç”Ÿæˆå›å¤ | è¾“å…¥å†å²è®°å½•æ•°é‡: {len(history)} | ä¸Šä¸‹æ–‡æ¥æº: {session_context_source or 'å¸¸è§„'}")
        if history:
            print("ğŸ“œ è¾“å…¥å†å²è®°å½•:")
            for i, msg in enumerate(history):
                role_emoji = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
                print(f"  [{i+1}] {role_emoji} {msg['role']}")
                # é™åˆ¶å†…å®¹é•¿åº¦
                content_preview = msg['content'][:80] + "..." if len(msg['content']) > 80 else msg['content']
                print(f"      ğŸ“ {content_preview}")
        else:
            print("ğŸ“œ è¾“å…¥å†å²è®°å½•ä¸ºç©º")

        # æ„å»º prompt
        messages = []
        
        # 1. æ·»åŠ  system_prompt
        if "system_prompt" in role_data:
            messages.append({"role": "system", "content": role_data["system_prompt"]})
        
        # 2. ä»…åœ¨éå¿«ç…§ä¼šè¯æ—¶æ·»åŠ è§’è‰²é¢„ç½® historyï¼ˆé¿å…é‡å¤ï¼‰
        if session_context_source != "snapshot" and "history" in role_data:
            messages.extend(role_data["history"])
            print(f"âœ… æ·»åŠ è§’è‰²é¢„ç½®å¯¹è¯: {len(role_data.get('history', []))} æ¡")
        elif session_context_source == "snapshot":
            print(f"â­ï¸ è·³è¿‡è§’è‰²é¢„ç½®å¯¹è¯ï¼ˆå¿«ç…§ä¼šè¯å·²åŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡ï¼‰")
        
        # 3. æ·»åŠ å®é™…ä¼šè¯å†å²
        messages.extend(history)
        # æ³¨æ„ï¼šä¸å†é¢å¤–æ·»åŠ  user_inputï¼Œå› ä¸ºå®ƒå·²ç»åœ¨ history ä¸­äº†

        # æ‰“å°æ„å»ºçš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨
        print(f"ğŸ”§ æ„å»ºå®Œæ•´æ¶ˆæ¯åˆ—è¡¨ | æ€»æ¶ˆæ¯æ•°: {len(messages)}")
        print("ğŸ“‹ å®Œæ•´æ¶ˆæ¯åˆ—è¡¨:")
        for i, msg in enumerate(messages):
            role_emoji = {"system": "âš™ï¸", "user": "ğŸ‘¤", "assistant": "ğŸ¤–"}.get(msg["role"], "â“")
            print(f"  [{i+1}] {role_emoji} {msg['role']}")
            content_preview = msg['content'][:80] + "..." if len(msg['content']) > 80 else msg['content']
            print(f"      ğŸ“ {content_preview}")
        
        print(f"ğŸ‘¤ å½“å‰ç”¨æˆ·è¾“å…¥: {user_input}")
        print("ğŸ§ " + "="*48)

        # æ¨¡æ‹Ÿè¶…æ—¶
        # ï¼ˆè¿™é‡Œåº”è¯¥åœ¨ GPTCaller å±‚åšçœŸæ­£çš„ async è¶…æ—¶æ§åˆ¶ï¼Œè¿™é‡Œå…ˆç®€åŒ–ï¼‰
        if random.random() < 0.01:
            raise TimeoutError("4004: ç”Ÿæˆè¶…æ—¶")

        # å¼€å§‹è®¡æ—¶ï¼šä»è°ƒç”¨GPT APIå¼€å§‹
        start = time.time()
        
        # æ”¶é›†å®Œæ•´å›å¤
        full_response = ""
        
        # è°ƒç”¨å¼‚æ­¥æµå¼ GPT API
        async for partial_reply in self.gpt.get_stream_response(messages, model_name=role_data.get("model"), timeout=timeout):
            full_response += partial_reply
            
            # å¦‚æœæä¾›äº†å›è°ƒå‡½æ•°ï¼Œé€æ­¥è°ƒç”¨å®ƒæ¥å¤„ç†éƒ¨åˆ†å›å¤
            if on_partial_reply:
                if callable(on_partial_reply):
                    # åŒæ­¥å›è°ƒ
                    on_partial_reply(partial_reply)
                else:
                    # å¼‚æ­¥å›è°ƒ
                    await on_partial_reply(partial_reply)

        # ç»“æŸæµå¼ç”Ÿæˆ
        print(f"ğŸ¤– AIç”Ÿæˆå›å¤å®Œæˆ | è€—æ—¶: {time.time() - start:.2f}ç§’ | æ€»å­—ç¬¦æ•°: {len(full_response)}")
        print("ğŸ¤–" + "="*48)
        
        return full_response

    async def generate_reply_stream(self, role_data, history, user_input, timeout=30, session_context_source=None) -> AsyncGenerator[str, None]:
        """
        æµå¼ç”ŸæˆAIå›å¤ - è¿”å›å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œç”¨äºTelegram Botçš„æµå¼æ›´æ–°
        
        Args:
            role_data: è§’è‰²é…ç½®æ•°æ®
            history: ä¼šè¯å†å²æ¶ˆæ¯
            user_input: å½“å‰ç”¨æˆ·è¾“å…¥
            timeout: è¶…æ—¶æ—¶é—´
            session_context_source: ä¼šè¯ä¸Šä¸‹æ–‡æ¥æºæ ‡è®°
            
        Yields:
            str: æ¯ä¸ªæµå¼å›å¤ç‰‡æ®µ
        """
        # æ‰“å°è¾“å…¥çš„å†å²è®°å½•
        print(f"ğŸ§  AIæµå¼ç”Ÿæˆå›å¤ | è¾“å…¥å†å²è®°å½•æ•°é‡: {len(history)} | ä¸Šä¸‹æ–‡æ¥æº: {session_context_source or 'å¸¸è§„'}")
        
        # æ„å»º promptï¼ˆå¤ç”¨ç›¸åŒé€»è¾‘ï¼‰
        messages = []
        
        # 1. æ·»åŠ  system_prompt
        if "system_prompt" in role_data:
            messages.append({"role": "system", "content": role_data["system_prompt"]})
        
        # 2. ä»…åœ¨éå¿«ç…§ä¼šè¯æ—¶æ·»åŠ è§’è‰²é¢„ç½® historyï¼ˆé¿å…é‡å¤ï¼‰
        if session_context_source != "snapshot" and "history" in role_data:
            messages.extend(role_data["history"])
            print(f"âœ… æ·»åŠ è§’è‰²é¢„ç½®å¯¹è¯: {len(role_data.get('history', []))} æ¡")
        elif session_context_source == "snapshot":
            print(f"â­ï¸ è·³è¿‡è§’è‰²é¢„ç½®å¯¹è¯ï¼ˆå¿«ç…§ä¼šè¯å·²åŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡ï¼‰")
        
        # 3. æ·»åŠ å®é™…ä¼šè¯å†å²
        messages.extend(history)
        
        print(f"ğŸ”§ æ„å»ºå®Œæ•´æ¶ˆæ¯åˆ—è¡¨ | æ€»æ¶ˆæ¯æ•°: {len(messages)}")
        print("ğŸ§ " + "="*48)

        # æ¨¡æ‹Ÿè¶…æ—¶
        if random.random() < 0.01:
            raise TimeoutError("4004: ç”Ÿæˆè¶…æ—¶")

        # å¼€å§‹è®¡æ—¶
        start = time.time()
        
        # æµå¼ç”Ÿæˆå¹¶é€æ­¥è¿”å›
        async for partial_reply in self.gpt.get_stream_response(messages, model_name=role_data.get("model"), timeout=timeout):
            yield partial_reply

        # ç»“æŸæµå¼ç”Ÿæˆ
        print(f"ğŸ¤– AIæµå¼ç”Ÿæˆå®Œæˆ | è€—æ—¶: {time.time() - start:.2f}ç§’")
        print("ğŸ¤–" + "="*48)


# âœ… å…¨å±€å”¯ä¸€å®ä¾‹ - ä¸å…¶ä»–æœåŠ¡ä¿æŒä¸€è‡´çš„è®¾è®¡æ¨¡å¼

from demo.novel_async import AsyncNovelCaller
ai_completion_port = AICompletionPort(AsyncNovelCaller())
