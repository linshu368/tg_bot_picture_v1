# main.py - æµå¼å›å¤æµ‹è¯•ç‰ˆæœ¬
from role import role_data
from api import GPTCaller
import sys

conversation_history = []

def build_messages(user_input):
    messages = []
    if "system_prompt" in role_data:
        messages.append({"role": "system", "content": role_data["system_prompt"]})
    if "history" in role_data:
        messages.extend(role_data["history"])
    messages.extend(conversation_history)
    messages.append({"role": "user", "content": user_input})
    return messages


if __name__ == "__main__":
    gpt = GPTCaller()
    
    print(f"ğŸ­ å½“å‰è§’è‰²: {role_data['name']}")
    print(f"ğŸ“ è§’è‰²ä»‹ç»: {role_data['summary']}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {role_data.get('model')}")
    print("="*50)

    while True:
        user_input = input("\nğŸ‘¤ ä½ : ")
        if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
            print("ğŸ‘‹ å¯¹è¯ç»“æŸ")
            break

        messages = build_messages(user_input)

        # ğŸ‘‡ ä½¿ç”¨è§’è‰²æŒ‡å®šçš„æ¨¡å‹ï¼ˆè‹¥æ²¡å†™ï¼Œå°±ç”¨é»˜è®¤ï¼‰
        model_name = role_data.get("model")

        # âœ… æµå¼è¾“å‡º - é€å­—æ˜¾ç¤ºå›å¤
        print(f"ğŸ¤– {role_data['name']}: ", end='', flush=True)
        
        full_response = ""
        try:
            for chunk in gpt.get_stream_response(messages, model_name=model_name):
                print(chunk, end='', flush=True)  # é€å­—æ‰“å°
                full_response += chunk
            print()  # æ¢è¡Œ
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            continue

        # ä¿å­˜åˆ°å¯¹è¯å†å²
        conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": full_response})
