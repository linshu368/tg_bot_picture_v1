# main_async.py - å¼‚æ­¥æµå¼å›å¤æµ‹è¯•ç‰ˆæœ¬
import asyncio
import time
import sys
import json
import aiohttp
from role import role_data

conversation_history = []

async def chat_with_ai_async(messages, api_key, model_name, debug=False):
    """
    ä½¿ç”¨ä¸test1.pyç›¸åŒçš„æ–¹å¼å¼‚æ­¥è°ƒç”¨API
    """
    url = "https://www.gpt4novel.com/api/xiaoshuoai/ext/v1/chat/completions"
    
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {api_key}',
    }
    
    # æ„å»ºè¯·æ±‚ä½“ - ä¸test1.pyå®Œå…¨ç›¸åŒ
    request_body = {
        'model': model_name,
        'messages': messages,
        'stream': True,
        'temperature': 0.7,
        'max_tokens': 800,
        'top_p': 0.35,
        'repetition_penalty': 1.05,
    }
    
    if debug:
        print(f"[API] å‘èµ·è¯·æ±‚åˆ°: {url}")
        print(f"[API] ä½¿ç”¨æ¨¡å‹: {model_name}")
        print(f"[API] æ¶ˆæ¯æ•°é‡: {len(messages)}")
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(url, headers=headers, json=request_body) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise ValueError(f"HTTP error! status: {response.status}, response: {error_text}")
                
                if debug:
                    print(f"[API] è¯·æ±‚æˆåŠŸï¼Œå¼€å§‹è¯»å–æµ...")
                
                # å¤„ç†æµå“åº”
                buffer = ''
                async for chunk in response.content.iter_chunked(1024):
                    if chunk:
                        decoded_chunk = chunk.decode('utf-8')
                        buffer += decoded_chunk
                        
                        # æŒ‰è¡Œå¤„ç†æ•°æ® - å¤„ç†SSEæ ¼å¼
                        while '\n' in buffer:
                            line, buffer = buffer.split('\n', 1)
                            if line.strip():
                                try:
                                    # å¤„ç†SSEæ ¼å¼ï¼šå»æ‰ "data: " å‰ç¼€
                                    if line.strip().startswith('data: '):
                                        json_str = line.strip()[6:]  # å»æ‰ "data: " å‰ç¼€
                                        if json_str.strip():  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                                            json_data = json.loads(json_str)
                                            if 'choices' in json_data:
                                                content = json_data['choices'][0].get('delta', {}).get('content', '')
                                                if content:
                                                    yield content
                                except json.JSONDecodeError:
                                    if debug:
                                        print(f"[API] æ— æ³•è§£ææ•°æ®ï¼š{line.strip()}")
                                    continue
                                    
    except Exception as e:
        if debug:
            print(f"[API] è¯·æ±‚å¤±è´¥: {str(e)}")
        raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {str(e)}")

def build_messages(user_input):
    messages = []
    if "system_prompt" in role_data:
        messages.append({"role": "system", "content": role_data["system_prompt"]})
    if "history" in role_data:
        messages.extend(role_data["history"])
    messages.extend(conversation_history)
    messages.append({"role": "user", "content": user_input})
    return messages

async def granular_stream_display(api_key, messages, model_name, debug=False):
    """
    ç²¾ç»†åŒ–æµå¼æ˜¾ç¤ºï¼š
    1. å‰5ä¸ªå­—ç¬¦ç«‹å³æ˜¾ç¤º
    2. ä¹‹åæ¯2ç§’æ›´æ–°ä¸€æ¬¡
    3. ç”Ÿæˆå®Œæˆç«‹å³æ˜¾ç¤º
    """
    accumulated_text = ""
    char_count = 0
    first_chars_threshold = 5  # å‰5ä¸ªå­—ç¬¦ç«‹å³æ˜¾ç¤º
    regular_update_interval = 2.0  # 2ç§’é—´éš”
    last_update_time = 0
    last_displayed_length = 0  # è®°å½•ä¸Šæ¬¡æ˜¾ç¤ºçš„é•¿åº¦
    
    # é˜¶æ®µæ ‡è®°
    phase = "collecting_first_chars"  # collecting_first_chars -> regular_updates -> completed
    
    # â±ï¸ æ—¶é—´æ—¥å¿—
    start_time = time.time()
    first_chunk_time = None
    first_5chars_time = None
    update_times = []  # è®°å½•æ¯æ¬¡æ›´æ–°çš„æ—¶é—´
    
    print("âœï¸è¾“å…¥ä¸­...", end='', flush=True)
    print(f"\n[â±ï¸ è¯·æ±‚å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}]")
    
    try:
        async for chunk in chat_with_ai_async(messages, api_key, model_name, debug=debug):
            # è®°å½•ç¬¬ä¸€ä¸ªchunkåˆ°è¾¾æ—¶é—´
            if first_chunk_time is None:
                first_chunk_time = time.time()
                elapsed = first_chunk_time - start_time
                print(f"[â±ï¸ é¦–ä¸ªchunkåˆ°è¾¾: +{elapsed:.3f}ç§’]")
            
            # é€å­—ç¬¦å¤„ç†ï¼Œå®ç°ç²¾ç¡®æ§åˆ¶
            for char in chunk:
                accumulated_text += char
                char_count = len(accumulated_text)
                current_time = time.time()
                
                if phase == "collecting_first_chars":
                    # é˜¶æ®µ1ï¼šæ”¶é›†å‰5ä¸ªå­—ç¬¦åç«‹å³æ›´æ–°
                    if char_count >= first_chars_threshold:
                        first_5chars_time = current_time
                        elapsed_from_start = first_5chars_time - start_time
                        elapsed_from_first_chunk = first_5chars_time - first_chunk_time
                        
                        # æ¸…é™¤"è¾“å…¥ä¸­..."å¹¶æ˜¾ç¤ºå‰5ä¸ªå­—ç¬¦
                        print("\r" + " " * 10 + "\r", end='', flush=True)  # æ¸…é™¤ä¹‹å‰çš„æ–‡æœ¬
                        print(accumulated_text, end='', flush=True)
                        last_displayed_length = len(accumulated_text)
                        phase = "regular_updates"
                        last_update_time = current_time
                        
                        print(f"\n[â±ï¸ å‰5å­—ç¬¦æ˜¾ç¤º: æ€»è€—æ—¶{elapsed_from_start:.3f}ç§’, ä»é¦–chunk{elapsed_from_first_chunk:.3f}ç§’]", end='', flush=True)
                        update_times.append(("é¦–æ®µæ˜¾ç¤º", elapsed_from_start))
                        
                elif phase == "regular_updates":
                    # é˜¶æ®µ2ï¼šæ¯2ç§’æ›´æ–°ä¸€æ¬¡
                    if current_time - last_update_time >= regular_update_interval:
                        elapsed = current_time - start_time
                        interval = current_time - last_update_time
                        
                        # æ¸…é™¤ä¹‹å‰æ˜¾ç¤ºçš„å†…å®¹å¹¶æ˜¾ç¤ºæ–°å†…å®¹
                        clear_length = last_displayed_length + 20  # é¢å¤–æ¸…é™¤æ ‡è®°æ–‡æœ¬
                        print("\r" + " " * clear_length + "\r", end='', flush=True)
                        print(accumulated_text, end='', flush=True)
                        last_displayed_length = len(accumulated_text)
                        last_update_time = current_time
                        
                        print(f"\n[â±ï¸ å®šæ—¶æ›´æ–°: æ€»è€—æ—¶{elapsed:.3f}ç§’, é—´éš”{interval:.3f}ç§’, {char_count}å­—ç¬¦]", end='', flush=True)
                        update_times.append(("å®šæ—¶æ›´æ–°", elapsed))
        
        # é˜¶æ®µ3ï¼šç«‹å³æœ€ç»ˆæ›´æ–°
        if accumulated_text:
            end_time = time.time()
            total_elapsed = end_time - start_time
            
            # æ¸…é™¤ä¹‹å‰æ˜¾ç¤ºçš„å†…å®¹å¹¶æ˜¾ç¤ºæœ€ç»ˆå†…å®¹
            clear_length = last_displayed_length + 30
            print("\r" + " " * clear_length + "\r", end='', flush=True)
            print(accumulated_text, end='', flush=True)
            
            print(f"\n[âœ… å®Œæˆ: æ€»è€—æ—¶{total_elapsed:.3f}ç§’, å…±{len(accumulated_text)}å­—ç¬¦]")
            print(f"[â±ï¸ å¹³å‡é€Ÿåº¦: {len(accumulated_text)/total_elapsed:.1f}å­—ç¬¦/ç§’]")
            
            # æ‰“å°è¯¦ç»†æ—¶é—´çº¿
            print("\nğŸ“Š æ—¶é—´çº¿è¯¦æƒ…:")
            print(f"  è¯·æ±‚å‘èµ· -> é¦–ä¸ªchunk: {(first_chunk_time - start_time) if first_chunk_time else 0:.3f}ç§’")
            if first_5chars_time:
                print(f"  è¯·æ±‚å‘èµ· -> å‰5å­—ç¬¦: {(first_5chars_time - start_time):.3f}ç§’")
            print(f"  è¯·æ±‚å‘èµ· -> å…¨éƒ¨å®Œæˆ: {total_elapsed:.3f}ç§’")
        
    except Exception as e:
        print(f"\nâŒ æµå¼æ˜¾ç¤ºé”™è¯¯: {e}")
        raise

async def collect_full_response(api_key, messages, model_name, debug=False):
    """æ”¶é›†å®Œæ•´å“åº”ç”¨äºä¿å­˜åˆ°å†å²è®°å½•"""
    full_response = ""
    try:
        async for chunk in chat_with_ai_async(messages, api_key, model_name, debug=False):  # æ”¶é›†æ—¶ä¸æ‰“å°debugæ—¥å¿—
            full_response += chunk
        return full_response
    except Exception as e:
        print(f"âŒ æ”¶é›†å“åº”é”™è¯¯: {e}")
        return ""

async def main():
    # ğŸ”§ APIé…ç½® - ç›´æ¥ä½¿ç”¨test1.pyä¸­æˆåŠŸçš„é…ç½®
    API_KEY = "a80bb032-61d7-4a6a-8271-11f5aadc47f8"  # ä½ çš„APIå¯†é’¥
    MODEL_NAME = "nalang-xl-0826-10k"  # ä½ çš„æ¨¡å‹åç§°
    
    # ğŸ” è®¾ç½®è°ƒè¯•æ¨¡å¼
    DEBUG_MODE = True  # æ”¹ä¸ºFalseå¯å…³é—­APIè¯¦ç»†æ—¥å¿—
    
    print(f"ğŸ­ å½“å‰è§’è‰²: {role_data['name']}")
    print(f"ğŸ“ è§’è‰²ä»‹ç»: {role_data['summary']}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {role_data.get('model')}")
    print(f"ğŸ” è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if DEBUG_MODE else 'å…³é—­'}")
    print("="*50)

    while True:
        user_input = input("\nğŸ‘¤ ä½ : ")
        if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
            print("ğŸ‘‹ å¯¹è¯ç»“æŸ")
            break

        messages = build_messages(user_input)

        # ğŸ‘‡ ä½¿ç”¨è§’è‰²æŒ‡å®šçš„æ¨¡å‹ï¼ˆè‹¥æ²¡å†™ï¼Œå°±ç”¨é»˜è®¤ï¼‰
        model_name = role_data.get("model", MODEL_NAME)

        # âœ… ç²¾ç»†åŒ–æµå¼è¾“å‡º - 5å­—ç¬¦ç«‹å³æ˜¾ç¤ºï¼Œç„¶åæ¯2ç§’æ›´æ–°
        print(f"ğŸ¤– {role_data['name']}: ", end='', flush=True)
        
        full_response = ""
        try:
            await granular_stream_display(API_KEY, messages, model_name, debug=DEBUG_MODE)
            full_response = await collect_full_response(API_KEY, messages, model_name, debug=DEBUG_MODE)
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            continue

        # ä¿å­˜åˆ°å¯¹è¯å†å²
        conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    asyncio.run(main())
