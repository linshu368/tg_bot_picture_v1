# main_async.py - å¼‚æ­¥æµå¼å›å¤æµ‹è¯•ç‰ˆæœ¬
import asyncio
import time
import os
from role import role_data
from grok_async import chat_with_grok_async

conversation_history = []


async def chat_with_ai_async(messages, api_key, model_name, debug=False):
    """ä½¿ç”¨grok_async.pyä¸­çš„å‡½æ•°è°ƒç”¨API"""
    if debug:
        print(f"[API] ä½¿ç”¨Grok API")
        print(f"[API] ä½¿ç”¨æ¨¡å‹: {model_name}")
        print(f"[API] æ¶ˆæ¯æ•°é‡: {len(messages)}")
    
    try:
        # ç›´æ¥è°ƒç”¨grok_async.pyä¸­çš„å‡½æ•°ï¼Œä¼ å…¥æ¨¡å‹åç§°
        async for content in chat_with_grok_async(messages, api_key, model_name, debug=debug):
            yield content
                    
    except Exception as e:
        if debug:
            print(f"[API] è¯·æ±‚å¤±è´¥: {str(e)}")
        raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {str(e)}")


def build_messages(user_input):
    """æ„å»ºæ¶ˆæ¯åˆ—è¡¨"""
    messages = []
    
    # æ·»åŠ ç³»ç»Ÿæç¤º
    if "system_prompt" in role_data:
        messages.append({"role": "system", "content": role_data["system_prompt"]})
    
    # æ·»åŠ å†å²è®°å½•
    if "history" in role_data:
        messages.extend(role_data["history"])
    
    # æ·»åŠ å¯¹è¯å†å²
    messages.extend(conversation_history)
    
    # æ·»åŠ ç”¨æˆ·è¾“å…¥
    messages.append({"role": "user", "content": user_input})
    
    return messages


async def granular_stream_display(api_key, messages, model_name, debug=False):
    """
    ç²¾ç»†åŒ–æµå¼æ˜¾ç¤ºï¼š
    1. å‰5ä¸ªå­—ç¬¦ç«‹å³æ˜¾ç¤º
    2. ä¹‹åæ¯2ç§’æ›´æ–°ä¸€æ¬¡
    3. ç”Ÿæˆå®Œæˆç«‹å³æ˜¾ç¤º
    """
    accumulated_text = ""
    char_count = 0
    first_chars_threshold = 5  # å‰5ä¸ªå­—ç¬¦ç«‹å³æ˜¾ç¤º
    regular_update_interval = 2.0  # 2ç§’é—´éš”
    last_update_time = 0
    last_displayed_length = 0  # è®°å½•ä¸Šæ¬¡æ˜¾ç¤ºçš„é•¿åº¦
    
    # é˜¶æ®µæ ‡è®°
    phase = "collecting_first_chars"  # collecting_first_chars -> regular_updates -> completed
    
    # â±ï¸ æ—¶é—´æ—¥å¿—
    start_time = time.time()
    first_chunk_time = None
    first_5chars_time = None
    update_times = []  # è®°å½•æ¯æ¬¡æ›´æ–°çš„æ—¶é—´
    
    print("âœï¸è¾“å…¥ä¸­...", end='', flush=True)
    print(f"\n[â±ï¸ è¯·æ±‚å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}]")
    
    try:
        async for chunk in chat_with_ai_async(messages, api_key, model_name, debug=debug):
            # è®°å½•ç¬¬ä¸€ä¸ªchunkåˆ°è¾¾æ—¶é—´
            if first_chunk_time is None:
                first_chunk_time = time.time()
                elapsed = first_chunk_time - start_time
                print(f"[â±ï¸ é¦–ä¸ªchunkåˆ°è¾¾: +{elapsed:.3f}ç§’]")
            
            # é€å­—ç¬¦å¤„ç†ï¼Œå®ç°ç²¾ç¡®æ§åˆ¶
            for char in chunk:
                accumulated_text += char
                char_count = len(accumulated_text)
                current_time = time.time()
                
                if phase == "collecting_first_chars":
                    # é˜¶æ®µ1ï¼šæ”¶é›†å‰5ä¸ªå­—ç¬¦åç«‹å³æ›´æ–°
                    if char_count >= first_chars_threshold:
                        first_5chars_time = current_time
                        elapsed_from_start = first_5chars_time - start_time
                        elapsed_from_first_chunk = first_5chars_time - first_chunk_time
                        
                        # æ¸…é™¤"è¾“å…¥ä¸­..."å¹¶æ˜¾ç¤ºå‰5ä¸ªå­—ç¬¦
                        print("\r" + " " * 10 + "\r", end='', flush=True)  # æ¸…é™¤ä¹‹å‰çš„æ–‡æœ¬
                        print(accumulated_text, end='', flush=True)
                        last_displayed_length = len(accumulated_text)
                        phase = "regular_updates"
                        last_update_time = current_time
                        
                        print(f"\n[â±ï¸ å‰5å­—ç¬¦æ˜¾ç¤º: æ€»è€—æ—¶{elapsed_from_start:.3f}ç§’, ä»é¦–chunk{elapsed_from_first_chunk:.3f}ç§’]", end='', flush=True)
                        update_times.append(("é¦–æ®µæ˜¾ç¤º", elapsed_from_start))
                        
                elif phase == "regular_updates":
                    # é˜¶æ®µ2ï¼šæ¯2ç§’æ›´æ–°ä¸€æ¬¡
                    if current_time - last_update_time >= regular_update_interval:
                        elapsed = current_time - start_time
                        interval = current_time - last_update_time
                        
                        # æ¸…é™¤ä¹‹å‰æ˜¾ç¤ºçš„å†…å®¹å¹¶æ˜¾ç¤ºæ–°å†…å®¹
                        clear_length = last_displayed_length + 20  # é¢å¤–æ¸…é™¤æ ‡è®°æ–‡æœ¬
                        print("\r" + " " * clear_length + "\r", end='', flush=True)
                        print(accumulated_text, end='', flush=True)
                        last_displayed_length = len(accumulated_text)
                        last_update_time = current_time
                        
                        print(f"\n[â±ï¸ å®šæ—¶æ›´æ–°: æ€»è€—æ—¶{elapsed:.3f}ç§’, é—´éš”{interval:.3f}ç§’, {char_count}å­—ç¬¦]", end='', flush=True)
                        update_times.append(("å®šæ—¶æ›´æ–°", elapsed))
        
        # é˜¶æ®µ3ï¼šç«‹å³æœ€ç»ˆæ›´æ–°
        if accumulated_text:
            end_time = time.time()
            total_elapsed = end_time - start_time
            
            # æ¸…é™¤ä¹‹å‰æ˜¾ç¤ºçš„å†…å®¹å¹¶æ˜¾ç¤ºæœ€ç»ˆå†…å®¹
            clear_length = last_displayed_length + 30
            print("\r" + " " * clear_length + "\r", end='', flush=True)
            print(accumulated_text, end='', flush=True)
            
            print(f"\n[âœ… å®Œæˆ: æ€»è€—æ—¶{total_elapsed:.3f}ç§’, å…±{len(accumulated_text)}å­—ç¬¦]")
            print(f"[â±ï¸ å¹³å‡é€Ÿåº¦: {len(accumulated_text)/total_elapsed:.1f}å­—ç¬¦/ç§’]")
            
            # æ‰“å°è¯¦ç»†æ—¶é—´çº¿
            print("\nğŸ“Š æ—¶é—´çº¿è¯¦æƒ…:")
            print(f"  è¯·æ±‚å‘èµ· -> é¦–ä¸ªchunk: {(first_chunk_time - start_time) if first_chunk_time else 0:.3f}ç§’")
            if first_5chars_time:
                print(f"  è¯·æ±‚å‘èµ· -> å‰5å­—ç¬¦: {(first_5chars_time - start_time):.3f}ç§’")
            print(f"  è¯·æ±‚å‘èµ· -> å…¨éƒ¨å®Œæˆ: {total_elapsed:.3f}ç§’")
        
    except Exception as e:
        print(f"\nâŒ æµå¼æ˜¾ç¤ºé”™è¯¯: {e}")
        raise


async def collect_full_response(api_key, messages, model_name, debug=False):
    """æ”¶é›†å®Œæ•´å“åº”ç”¨äºä¿å­˜åˆ°å†å²è®°å½•"""
    full_response = ""
    try:
        async for chunk in chat_with_ai_async(messages, api_key, model_name, debug=False):
            full_response += chunk
        return full_response
    except Exception as e:
        print(f"âŒ æ”¶é›†å“åº”é”™è¯¯: {e}")
        return ""


async def main():
    # ğŸ”§ APIé…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–
    API_KEY = os.getenv("GROK_API_KEY")
    MODEL_NAME = os.getenv("GROK_MODEL_NAME", "grok-4-fast-non-reasoning")  # é»˜è®¤æ¨¡å‹
    
    # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦è®¾ç½®
    if not API_KEY:
        print("âŒ é”™è¯¯: è¯·è®¾ç½® GROK_API_KEY ç¯å¢ƒå˜é‡")
        print("ğŸ’¡ æç¤º: åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ : GROK_API_KEY=ä½ çš„APIå¯†é’¥")
        return
    
    # ğŸ” è®¾ç½®è°ƒè¯•æ¨¡å¼
    DEBUG_MODE = True  # æ”¹ä¸ºFalseå¯å…³é—­APIè¯¦ç»†æ—¥å¿—
    
    print(f"ğŸ­ å½“å‰è§’è‰²: {role_data['name']}")
    print(f"ğŸ“ è§’è‰²ä»‹ç»: {role_data['summary']}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {role_data.get('model', MODEL_NAME)}")
    print(f"ğŸ”‘ APIå¯†é’¥: {API_KEY[:10]}...{API_KEY[-10:] if API_KEY else 'æœªè®¾ç½®'}")
    print(f"ğŸ” è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if DEBUG_MODE else 'å…³é—­'}")
    print("=" * 50)

    while True:
        user_input = input("\nğŸ‘¤ ä½ : ")
        if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
            print("ğŸ‘‹ å¯¹è¯ç»“æŸ")
            break

        messages = build_messages(user_input)

        # ğŸ‘‡ ä½¿ç”¨è§’è‰²æŒ‡å®šçš„æ¨¡å‹ï¼ˆè‹¥æ²¡å†™ï¼Œå°±ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤æ¨¡å‹ï¼‰
        model_name = role_data.get("model", MODEL_NAME)

        # âœ… ç²¾ç»†åŒ–æµå¼è¾“å‡º - 5å­—ç¬¦ç«‹å³æ˜¾ç¤ºï¼Œç„¶åæ¯2ç§’æ›´æ–°
        print(f"ğŸ¤– {role_data['name']}: ", end='', flush=True)
        
        full_response = ""
        try:
            await granular_stream_display(API_KEY, messages, model_name, debug=DEBUG_MODE)
            full_response = await collect_full_response(API_KEY, messages, model_name, debug=DEBUG_MODE)
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            continue

        # ä¿å­˜åˆ°å¯¹è¯å†å²
        conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": full_response})


if __name__ == "__main__":
    asyncio.run(main())