# main_async.py - å¼‚æ­¥æµå¼å›å¤æµ‹è¯•ç‰ˆæœ¬
import asyncio
import time
import sys
from role import role_data
from api_async import AsyncGPTCaller

conversation_history = []

def build_messages(user_input):
    messages = []
    if "system_prompt" in role_data:
        messages.append({"role": "system", "content": role_data["system_prompt"]})
    if "history" in role_data:
        messages.extend(role_data["history"])
    messages.extend(conversation_history)
    messages.append({"role": "user", "content": user_input})
    return messages

async def granular_stream_display(gpt, messages, model_name, debug=False):
    """
    ç²¾ç»†åŒ–æµå¼æ˜¾ç¤ºï¼š
    1. å‰5ä¸ªå­—ç¬¦ç«‹å³æ˜¾ç¤º
    2. ä¹‹åæ¯2ç§’æ›´æ–°ä¸€æ¬¡
    3. ç”Ÿæˆå®Œæˆç«‹å³æ˜¾ç¤º
    """
    accumulated_text = ""
    char_count = 0
    first_chars_threshold = 5  # å‰5ä¸ªå­—ç¬¦ç«‹å³æ˜¾ç¤º
    regular_update_interval = 2.0  # 2ç§’é—´éš”
    last_update_time = 0
    last_displayed_length = 0  # è®°å½•ä¸Šæ¬¡æ˜¾ç¤ºçš„é•¿åº¦
    
    # é˜¶æ®µæ ‡è®°
    phase = "collecting_first_chars"  # collecting_first_chars -> regular_updates -> completed
    
    # â±ï¸ æ—¶é—´æ—¥å¿—
    start_time = time.time()
    first_chunk_time = None
    first_5chars_time = None
    update_times = []  # è®°å½•æ¯æ¬¡æ›´æ–°çš„æ—¶é—´
    
    print("âœï¸è¾“å…¥ä¸­...", end='', flush=True)
    print(f"\n[â±ï¸ è¯·æ±‚å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}]")
    
    try:
        async for chunk in gpt.get_stream_response(messages, model_name=model_name, debug=debug):
            # è®°å½•ç¬¬ä¸€ä¸ªchunkåˆ°è¾¾æ—¶é—´
            if first_chunk_time is None:
                first_chunk_time = time.time()
                elapsed = first_chunk_time - start_time
                print(f"[â±ï¸ é¦–ä¸ªchunkåˆ°è¾¾: +{elapsed:.3f}ç§’]")
            
            # é€å­—ç¬¦å¤„ç†ï¼Œå®ç°ç²¾ç¡®æ§åˆ¶
            for char in chunk:
                accumulated_text += char
                char_count = len(accumulated_text)
                current_time = time.time()
                
                if phase == "collecting_first_chars":
                    # é˜¶æ®µ1ï¼šæ”¶é›†å‰5ä¸ªå­—ç¬¦åç«‹å³æ›´æ–°
                    if char_count >= first_chars_threshold:
                        first_5chars_time = current_time
                        elapsed_from_start = first_5chars_time - start_time
                        elapsed_from_first_chunk = first_5chars_time - first_chunk_time
                        
                        # æ¸…é™¤"è¾“å…¥ä¸­..."å¹¶æ˜¾ç¤ºå‰5ä¸ªå­—ç¬¦
                        print("\r" + " " * 10 + "\r", end='', flush=True)  # æ¸…é™¤ä¹‹å‰çš„æ–‡æœ¬
                        print(accumulated_text, end='', flush=True)
                        last_displayed_length = len(accumulated_text)
                        phase = "regular_updates"
                        last_update_time = current_time
                        
                        print(f"\n[â±ï¸ å‰5å­—ç¬¦æ˜¾ç¤º: æ€»è€—æ—¶{elapsed_from_start:.3f}ç§’, ä»é¦–chunk{elapsed_from_first_chunk:.3f}ç§’]", end='', flush=True)
                        update_times.append(("é¦–æ®µæ˜¾ç¤º", elapsed_from_start))
                        
                elif phase == "regular_updates":
                    # é˜¶æ®µ2ï¼šæ¯2ç§’æ›´æ–°ä¸€æ¬¡
                    if current_time - last_update_time >= regular_update_interval:
                        elapsed = current_time - start_time
                        interval = current_time - last_update_time
                        
                        # æ¸…é™¤ä¹‹å‰æ˜¾ç¤ºçš„å†…å®¹å¹¶æ˜¾ç¤ºæ–°å†…å®¹
                        clear_length = last_displayed_length + 20  # é¢å¤–æ¸…é™¤æ ‡è®°æ–‡æœ¬
                        print("\r" + " " * clear_length + "\r", end='', flush=True)
                        print(accumulated_text, end='', flush=True)
                        last_displayed_length = len(accumulated_text)
                        last_update_time = current_time
                        
                        print(f"\n[â±ï¸ å®šæ—¶æ›´æ–°: æ€»è€—æ—¶{elapsed:.3f}ç§’, é—´éš”{interval:.3f}ç§’, {char_count}å­—ç¬¦]", end='', flush=True)
                        update_times.append(("å®šæ—¶æ›´æ–°", elapsed))
        
        # é˜¶æ®µ3ï¼šç«‹å³æœ€ç»ˆæ›´æ–°
        if accumulated_text:
            end_time = time.time()
            total_elapsed = end_time - start_time
            
            # æ¸…é™¤ä¹‹å‰æ˜¾ç¤ºçš„å†…å®¹å¹¶æ˜¾ç¤ºæœ€ç»ˆå†…å®¹
            clear_length = last_displayed_length + 30
            print("\r" + " " * clear_length + "\r", end='', flush=True)
            print(accumulated_text, end='', flush=True)
            
            print(f"\n[âœ… å®Œæˆ: æ€»è€—æ—¶{total_elapsed:.3f}ç§’, å…±{len(accumulated_text)}å­—ç¬¦]")
            print(f"[â±ï¸ å¹³å‡é€Ÿåº¦: {len(accumulated_text)/total_elapsed:.1f}å­—ç¬¦/ç§’]")
            
            # æ‰“å°è¯¦ç»†æ—¶é—´çº¿
            print("\nğŸ“Š æ—¶é—´çº¿è¯¦æƒ…:")
            print(f"  è¯·æ±‚å‘èµ· -> é¦–ä¸ªchunk: {(first_chunk_time - start_time) if first_chunk_time else 0:.3f}ç§’")
            if first_5chars_time:
                print(f"  è¯·æ±‚å‘èµ· -> å‰5å­—ç¬¦: {(first_5chars_time - start_time):.3f}ç§’")
            print(f"  è¯·æ±‚å‘èµ· -> å…¨éƒ¨å®Œæˆ: {total_elapsed:.3f}ç§’")
        
    except Exception as e:
        print(f"\nâŒ æµå¼æ˜¾ç¤ºé”™è¯¯: {e}")
        raise

async def collect_full_response(gpt, messages, model_name, debug=False):
    """æ”¶é›†å®Œæ•´å“åº”ç”¨äºä¿å­˜åˆ°å†å²è®°å½•"""
    full_response = ""
    try:
        async for chunk in gpt.get_stream_response(messages, model_name=model_name, debug=False):  # æ”¶é›†æ—¶ä¸æ‰“å°debugæ—¥å¿—
            full_response += chunk
        return full_response
    except Exception as e:
        print(f"âŒ æ”¶é›†å“åº”é”™è¯¯: {e}")
        return ""

async def main():
    gpt = AsyncGPTCaller()
    
    # ğŸ” è®¾ç½®è°ƒè¯•æ¨¡å¼
    DEBUG_MODE = True  # æ”¹ä¸ºFalseå¯å…³é—­APIè¯¦ç»†æ—¥å¿—
    
    print(f"ğŸ­ å½“å‰è§’è‰²: {role_data['name']}")
    print(f"ğŸ“ è§’è‰²ä»‹ç»: {role_data['summary']}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {role_data.get('model')}")
    print(f"ğŸ” è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if DEBUG_MODE else 'å…³é—­'}")
    print("="*50)

    while True:
        user_input = input("\nğŸ‘¤ ä½ : ")
        if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
            print("ğŸ‘‹ å¯¹è¯ç»“æŸ")
            break

        messages = build_messages(user_input)

        # ğŸ‘‡ ä½¿ç”¨è§’è‰²æŒ‡å®šçš„æ¨¡å‹ï¼ˆè‹¥æ²¡å†™ï¼Œå°±ç”¨é»˜è®¤ï¼‰
        model_name = role_data.get("model")

        # âœ… ç²¾ç»†åŒ–æµå¼è¾“å‡º - 5å­—ç¬¦ç«‹å³æ˜¾ç¤ºï¼Œç„¶åæ¯2ç§’æ›´æ–°
        print(f"ğŸ¤– {role_data['name']}: ", end='', flush=True)
        
        full_response = ""
        try:
            await granular_stream_display(gpt, messages, model_name, debug=DEBUG_MODE)
            full_response = await collect_full_response(gpt, messages, model_name, debug=DEBUG_MODE)
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            continue

        # ä¿å­˜åˆ°å¯¹è¯å†å²
        conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    asyncio.run(main())
